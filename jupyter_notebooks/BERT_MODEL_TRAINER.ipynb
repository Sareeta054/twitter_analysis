{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT MODEL TRAINER.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JmDTQ-nUUcYj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LmzjvxRIS3wb"
      },
      "source": [
        "# Training a new model with 1.2 million tweets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2geFbcLqXwLU"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "6VswENZNRfUW",
        "outputId": "3a746336-39f1-47e7-c6f7-6878fd3a7188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ktrain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/0c/21c698b7986257248d2595d4e0b5368ac9cc1026cb88d8965b62cc551c2b/ktrain-0.6.2.tar.gz (173kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 5.1MB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.21.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.1.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.25.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.1.21)\n",
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.21.0)\n",
            "Collecting eli5>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 64.1MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.14.0)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.39)\n",
            "Collecting cchardet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/4e/847feebfc3e71c773b23ee06c74687b8c50a5a6d6aaff452a0a4f4eb9a32/cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 68.8MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.17.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (2.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->ktrain) (2018.9)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (2.10.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (0.8.5)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (19.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.3->ktrain) (4.4.1)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (19.2)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->ktrain) (41.6.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5>=0.10.0->ktrain) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh->ktrain) (0.46)\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: ktrain, keras-bert, seqeval, langdetect, networkx, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.6.2-cp36-none-any.whl size=223849 sha256=1a52f3eac276b9bf39b27ca7f5a56c97b2037dceed025dd4ad5130da01f13519\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/85/7b/0ccbcd5f821b73d1436f90895cb46064c10aca1ca3d083d384\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=14e86f19397661b634915c0ab16a78cdc3c372ce61d5a7833446d5b5a3e8b6d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=db8b326f7f9c11fa6a87cb2b329fae7796d273bcc1f9b8870e63e04c558dd374\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=2967cd294a6fea1212b4bcd7be465ccc716e560bcebc253f0c9b78057113f627\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=58888471f654d6b468f2656e3b95b1ff670271f233319e7cd74cb579d0d90fa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=0c7c594cab3d5f6709d35a342756eea5c6413f76cd9c688a839f556da9420356\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=8b37e62dc7b8890281c9fcc11a179c9b9136f75c159c51e47160c1244ba12466\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=2cd56e0828e957b98c3fe3f4f88d83dbb0d5d02ce303607ce8e3583793e882f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=1d3fa9ed3cce141eabe47df8b4935908885f918f7a6fbfe51c9c7bf10c6272c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=743134ae7deb3cefd8d2b1651785a167fee310f2b248936ffaf2eced67dd7d8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=f3390e3a06c11096dcfcdc07a37b340f7f2982d70b392c685d862f360e123590\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=4aa95611e9f47a9adf1c9dbbe5cdb600871301d47e8f73243eb046f7d23150f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built ktrain keras-bert seqeval langdetect networkx keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, eli5, seqeval, langdetect, cchardet, networkx, ktrain\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "Successfully installed cchardet-2.1.5 eli5-0.10.1 keras-2.2.4 keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0 ktrain-0.6.2 langdetect-1.0.7 networkx-2.3 seqeval-0.0.12\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using Keras version: 2.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain\n",
        "import pandas as pd\n",
        "import ktrain \n",
        "from ktrain import text\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "colab_type": "code",
        "id": "I_wO456ESxlD",
        "outputId": "06a8d21e-f732-41d9-93fd-26c7a4d2aaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "colab_type": "code",
        "id": "YuinL9atX6qG",
        "outputId": "bbbb81f3-87a8-4dfa-8e6f-26cf8ee738cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>my god this book is like listening to a record...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>need to go to bed now im wide awake too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>seems like a lacking concentration today even ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>crochet liberation front featured in inside cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>scoop: HASHTAG hasselhoff rushed to the hospit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION USER_MENTION and USER_MENTION ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION hi newbies. come and tweet with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION i thought i was being slick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>0</td>\n",
              "      <td>nooooooooooooo i cant hear max on the radio!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>1</td>\n",
              "      <td>just woke up!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         polarity                                           sentence\n",
              "0               0  my god this book is like listening to a record...\n",
              "1               0            need to go to bed now im wide awake too\n",
              "2               0  seems like a lacking concentration today even ...\n",
              "3               1  crochet liberation front featured in inside cr...\n",
              "4               0  scoop: HASHTAG hasselhoff rushed to the hospit...\n",
              "...           ...                                                ...\n",
              "1599995         1   USER_MENTION USER_MENTION and USER_MENTION ar...\n",
              "1599996         1   USER_MENTION hi newbies. come and tweet with ...\n",
              "1599997         1          USER_MENTION i thought i was being slick \n",
              "1599998         0    nooooooooooooo i cant hear max on the radio!!! \n",
              "1599999         1                                     just woke up! \n",
              "\n",
              "[1600000 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/senti_dataset/tweet_shuffled.csv', index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nLnvMdsBYebG"
      },
      "source": [
        "## Sampling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tIFzOyHRTVns"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 200000\n",
        "\n",
        "def training_generator(df, BATCH_SIZE):\n",
        "  x = []\n",
        "  y = []  \n",
        "  for row in df.itertuples():\n",
        "    if int(row.Index) % BATCH_SIZE == 0:\n",
        "      x = []\n",
        "      y = []\n",
        "    x.append(row.sentence)\n",
        "    y.append(row.polarity)\n",
        "    if int(row.Index + 1) % BATCH_SIZE == 0:\n",
        "      yield x,y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tnOVcW_I5jdy"
      },
      "outputs": [],
      "source": [
        "predictor_path = '/content/drive/My Drive/senti_model/' + 'tweetPredictor_'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KAP6jevY_8wf"
      },
      "outputs": [],
      "source": [
        "def return_last_predictor(predictor_path):\n",
        "  for j in range(10):\n",
        "    pred_full_path = predictor_path + str(j + 1)\n",
        "    if(not path.exists(pred_full_path)):\n",
        "      return j\n",
        "    else:\n",
        "      continue\n",
        "  return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "colab_type": "code",
        "id": "6DcNSym7A2aZ",
        "outputId": "b44d213c-ac2b-423a-a92f-ccb53a07e934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# return last trained predictor\n",
        "predictor_path = '/content/drive/My Drive/senti_model/' + 'tweetPredictor_'\n",
        "i = return_last_predictor(predictor_path)\n",
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "colab_type": "code",
        "id": "cQvr_ERSdTf8",
        "outputId": "86393134-bdba-42d4-978d-f1f62cc0f3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n",
            "['my god this book is like listening to a record on repeat 170,000 times. i get it! aid to africa hasnt &amp; wont help. shut the fuck up! ', 'need to go to bed now im wide awake too', 'seems like a lacking concentration today even though has to finish up her work asap ', 'crochet liberation front featured in inside crochet (uk) &quot;on the net&quot; section URL ', 'scoop: HASHTAG hasselhoff rushed to the hospital again 4 alcohol poisoning.daughter saves his life again. what happened 2 our knight rider ']\n",
            "['sipping a delicious cup of tea ', ' USER_MENTION ooo sounds like an awesome prize what do you have to do? ', 'cant believe susan boyle lost! ', 'enjoying the weekend with my baby doll ', 'boo to no internet due to the storm ']\n"
          ]
        }
      ],
      "source": [
        "for j in range(i,10):  \n",
        "  gen = training_generator(df, BATCH_SIZE)\n",
        "\n",
        "  # get to the i'th data batch\n",
        "  for k in range(i+1):\n",
        "    x, y = next(gen)\n",
        "    print(x[:5])\n",
        "\n",
        "  # i'th batch of data is processed further  \n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "  (x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=label_list,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=350, \n",
        "                                                                       max_features=35000,\n",
        "                                                                       lang='en')\n",
        "  x = None\n",
        "  y = None\n",
        "  if(i):\n",
        "    predictor_file = predictor_path + str(i)\n",
        "    pred = ktrain.load_predictor(predictor_file)\n",
        "    model = pred.model\n",
        "  learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=6)\n",
        "  learner.fit_onecycle(2e-5, 1)\n",
        "  predictor = ktrain.get_predictor(learner.model, preproc, )\n",
        "  predictor_path = '/content/drive/My Drive/senti_model/' + 'tweetPredictor_' + str(i + 1)\n",
        "  predictor.save(predictor_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_twfuUMMeqba"
      },
      "outputs": [],
      "source": [
        "next_x, next_y = next(gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "colab_type": "code",
        "id": "JN3MbsE0gGqB",
        "outputId": "4d569b63-5885-4fc9-8570-c6e7ec608744"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>my god this book is like listening to a record...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>need to go to bed now im wide awake too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>seems like a lacking concentration today even ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>crochet liberation front featured in inside cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>scoop: HASHTAG hasselhoff rushed to the hospit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity                                           sentence\n",
              "0         0  my god this book is like listening to a record...\n",
              "1         0            need to go to bed now im wide awake too\n",
              "2         0  seems like a lacking concentration today even ...\n",
              "3         1  crochet liberation front featured in inside cr...\n",
              "4         0  scoop: HASHTAG hasselhoff rushed to the hospit..."
            ]
          },
          "execution_count": 111,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "colab_type": "code",
        "id": "arysrSjMQzf9",
        "outputId": "6e0f07bd-c8b2-466a-c48f-eeabf16610da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's start from here\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=label_list,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=350, \n",
        "                                                                       max_features=35000,\n",
        "                                                                       lang='en')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wt2wEUSHgFNH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "90hx2EBcVO8-",
        "outputId": "34bfd8ad-063e-4f18-bd72-b2fb2a19931f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i cant believe the shaman drum bookshop is closing ', ' USER_MENTION i got one and like it', ' USER_MENTION thanks ', ' USER_MENTION thanks for the HASHTAG ! ', ' USER_MENTION nice. i miss the bay area hope you have a great monday and week!', 'i cant wait to see the new moon trailer tomorrow! omg sooo excited!', 'getting ready for the fiestaaa!! ', 'expects a boring day ', 'omg i just looked at my feet and they are a mess. dont wear shoes too small to go for a walk in the sun. ouch ', ' headed to the city for the last photoshoot in this weeks series. ill be under for the rest of the day but ill be back tomorrow!!', 'the only person you can trust is yourself.dont argue dont give me the usual bs.its my opinion &amp; it works for me. ', ' USER_MENTION its so nice. ', 'at gutted can see USER_MENTION tomorow ', 'my throat is killiinggg me not happy jan', ' USER_MENTION - thank you ', 'loneliness miss u so much t__t', ' USER_MENTION aww thanks baby! i love you ', 'bouncing on the mattress. my beds being taken down tonight. so long climbing frame ', ' USER_MENTION urgh, i got the same issue ', 'thinks its super cute that jake replayed viva la vida on youtube like 50x to learn the lyrics now he wont stop singing the whole thing ', 'up was the most depressing cartoon ive ever seen. going to cut my wrists when i get home with USER_MENTION ', ' USER_MENTION no way!!!!!! i wanna go tooo! we gotta figure out how to make that happen. ', ' USER_MENTION USER_MENTION she has now used the litter tray, and seems to be getting her bearings! more cat toilet updates tomorrow! ', 'ugh grumpy today think allergies are buggin me ', 'blair has a sextape? im disappointed, waldorf.', 'exam today, sleepy, hungry, ', 'my mom totally freaked me out! she started talking about this girl getting raped in cincinnati and i was like &quot;shut up!&quot;. ', 'its so cold and my sweater is in the car ', ' USER_MENTION ok thanks i am sooo tired ', ' USER_MENTION yea *high fives back*! ']\n",
            "[0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(x[:30])\n",
        "print(y[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Uqwoi-HCjDfE"
      },
      "outputs": [],
      "source": [
        "# unset the original data\n",
        "x = None\n",
        "y = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "colab_type": "code",
        "id": "cT_j6cA3RcO3",
        "outputId": "829feff2-b953-42b7-fead-c0153198c8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 350\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "# you can disregard the deprecation warnings arising from using Keras 2.2.4 with TensorFlow 1.14.\n",
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sscVCVSdms2U"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "colab_type": "code",
        "id": "rwOj9Ha7RqaV",
        "outputId": "7b981381-b67d-4526-9f08-710d6fd37e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/1\n",
            " 57522/160000 [=========>....................] - ETA: 5:09:32 - loss: 0.4213 - acc: 0.8077"
          ]
        }
      ],
      "source": [
        "learner.fit_onecycle(2e-5, 1)\n",
        "predictor = ktrain.get_predictor(learner.model, preproc, )\n",
        "predictor.save('/content/drive/My Drive/senti_model/tweetPredictor_firstepoch')\n",
        "learner.fit_onecycle(2e-5, 1)\n",
        "predictor = ktrain.get_predictor(learner.model, preproc, )\n",
        "predictor.save('/content/drive/My Drive/senti_model/tweetPredictor_secondepoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "colab_type": "code",
        "id": "cIbUcVjORxT1",
        "outputId": "c0bf630f-ae24-44f9-e118-fff3cb45f7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86     20000\n",
            "           4       0.86      0.85      0.85     20000\n",
            "\n",
            "    accuracy                           0.85     40000\n",
            "   macro avg       0.85      0.85      0.85     40000\n",
            "weighted avg       0.85      0.85      0.85     40000\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[17256,  2744],\n",
              "       [ 3098, 16902]])"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learner.validate(val_data=(x_test, y_test), class_names=[\"0\",\"1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gjJyTGS1R-69"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "colab_type": "code",
        "id": "E6zSvEJQSFHt",
        "outputId": "93d413ca-bfb4-4571-8891-e1ca32fa6d6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 4]"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re_predictor.get_classes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DauXcjpcSLe8"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/My Drive/senti_model/tweetPredictor_twoepoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "colab_type": "code",
        "id": "MHT1vROOr-KW",
        "outputId": "1f6fe1f0-0f80-46d2-da81-4b32a759b7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.7 GB  | Proc size: 2.0 GB\n",
            "GPU RAM Free: 10283MB | Used: 1158MB | Util  10% | Total 11441MB\n"
          ]
        }
      ],
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gZ8otln2t-Vs"
      },
      "outputs": [],
      "source": [
        "re_predictor = ktrain.load_predictor('/content/drive/My Drive/senti_model/tweetPredictor_oneepoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "Cbs7WDWVC5oj",
        "outputId": "ef3ac431-7293-457d-c564-f83cc9c8c071"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative result:  0.794513\n",
            "positive result:  0.000000\n"
          ]
        }
      ],
      "source": [
        "preds = re_predictor.predict(\"we should not kill immigrants\", return_proba=True)\n",
        "print(\"negative result:  %f\" %(preds[0]))\n",
        "print(\"positive result:  %f\" %(preds[]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "colab_type": "code",
        "id": "VsPNG_EkDIQY",
        "outputId": "92c977f4-62b8-465e-a7c8-65ad2ad34916"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4235dc7c11cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreloaded_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'reloaded_predictor' is not defined"
          ]
        }
      ],
      "source": [
        "reloaded_predictor.predict(\"\", return_proba=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mbiJ74bsEujr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "colab_type": "code",
        "id": "Ea8A_5bfUnNK",
        "outputId": "e95ac185-2911-421a-effc-68435532dd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "text",
        "id": "JmDTQ-nUUcYj"
      },
      "source": [
        "# Merging of datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "colab_type": "code",
        "id": "0WSsY1nGUf9A",
        "outputId": "acb380f3-b8da-49de-e493-a2ffec5395fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "uAZOEJL6Uf9M",
        "outputId": "b9354559-81ce-4cae-9146-d34f5b01b06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 7s 0us/step\n"
          ]
        }
      ],
      "source": [
        "train, test = download_and_load_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Us9EYqtQUf9T"
      },
      "outputs": [],
      "source": [
        "x_train = train.sentence\n",
        "y_train = train.polarity\n",
        "x_test = test.sentence\n",
        "y_test = test.polarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iDSSaYWgUf9j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = pd.concat([x_train, x_test]).reset_index()\n",
        "x = x.drop(['index'], axis=1)\n",
        "x\n",
        "\n",
        "y = pd.concat([y_train, y_test]).reset_index()\n",
        "y = y.drop(['index'], axis=1)\n",
        "y\n",
        "z = x.join(y)\n",
        "z\n",
        "z.to_csv('/content/drive/My Drive/senti_dataset/amazon_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "colab_type": "code",
        "id": "xUqus6I0Uf9q",
        "outputId": "8eaf4307-245c-4a11-f265-0ba81ecf2590"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941864</th>\n",
              "      <td>941865</td>\n",
              "      <td>1</td>\n",
              "      <td>HASHTAG psst you ya you ive got tweet. all yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690066</th>\n",
              "      <td>690067</td>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION damn. my parents wont let me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104253</th>\n",
              "      <td>1104254</td>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION USER_MENTION hmmm mustve missed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408070</th>\n",
              "      <td>408071</td>\n",
              "      <td>0</td>\n",
              "      <td>is gettin so frustrated designing tattoos but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062394</th>\n",
              "      <td>1062395</td>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION yeah it may smell funky but its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394804</th>\n",
              "      <td>394805</td>\n",
              "      <td>0</td>\n",
              "      <td>getting my study on for my final at 3. i need ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365926</th>\n",
              "      <td>365927</td>\n",
              "      <td>0</td>\n",
              "      <td>last night at the beach.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457262</th>\n",
              "      <td>457263</td>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION goodnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535553</th>\n",
              "      <td>1535554</td>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION we asked her if she had a name a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210057</th>\n",
              "      <td>210058</td>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION youre missing bgt thats depressing.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0  1                                                  2\n",
              "941864    941865  1   HASHTAG psst you ya you ive got tweet. all yo...\n",
              "690066    690067  0         USER_MENTION damn. my parents wont let me \n",
              "1104253  1104254  1   USER_MENTION USER_MENTION hmmm mustve missed ...\n",
              "408070    408071  0  is gettin so frustrated designing tattoos but ...\n",
              "1062394  1062395  1   USER_MENTION yeah it may smell funky but its ...\n",
              "...          ... ..                                                ...\n",
              "394804    394805  0  getting my study on for my final at 3. i need ...\n",
              "365926    365927  0                          last night at the beach. \n",
              "457262    457263  0                            USER_MENTION goodnight.\n",
              "1535553  1535554  1   USER_MENTION we asked her if she had a name a...\n",
              "210057    210058  0   USER_MENTION youre missing bgt thats depressing.\n",
              "\n",
              "[200000 rows x 3 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/senti_dataset/train_preprocessed_0and1.csv', header=None)\n",
        "small_df = df.sample(n=200000)\n",
        "small_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-r3d6I-FUf9x"
      },
      "outputs": [],
      "source": [
        "small_df = small_df.rename(columns={1: \"polarity\", 2: \"sentence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tjegqLUsUf92"
      },
      "outputs": [],
      "source": [
        "small_df = small_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "colab_type": "code",
        "id": "f69pOwVkUf99",
        "outputId": "8bf79dbf-b202-4278-e4b5-34f6739ae4ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>HASHTAG psst you ya you ive got tweet. all yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION damn. my parents wont let me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION USER_MENTION hmmm mustve missed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>is gettin so frustrated designing tattoos but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION yeah it may smell funky but its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0</td>\n",
              "      <td>getting my study on for my final at 3. i need ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>0</td>\n",
              "      <td>last night at the beach.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION goodnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION we asked her if she had a name a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0</td>\n",
              "      <td>USER_MENTION youre missing bgt thats depressing.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        polarity                                           sentence\n",
              "0              1   HASHTAG psst you ya you ive got tweet. all yo...\n",
              "1              0         USER_MENTION damn. my parents wont let me \n",
              "2              1   USER_MENTION USER_MENTION hmmm mustve missed ...\n",
              "3              0  is gettin so frustrated designing tattoos but ...\n",
              "4              1   USER_MENTION yeah it may smell funky but its ...\n",
              "...          ...                                                ...\n",
              "199995         0  getting my study on for my final at 3. i need ...\n",
              "199996         0                          last night at the beach. \n",
              "199997         0                            USER_MENTION goodnight.\n",
              "199998         1   USER_MENTION we asked her if she had a name a...\n",
              "199999         0   USER_MENTION youre missing bgt thats depressing.\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_df = small_df.drop(['index'], axis=1)\n",
        "small_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "colab_type": "code",
        "id": "yZ_yu2eSUf-D",
        "outputId": "b443f337-de84-45e4-9386-1943840e6350"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  sort=sort,\n"
          ]
        }
      ],
      "source": [
        "total = small_df.append(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vV9CmYuPUf-J"
      },
      "outputs": [],
      "source": [
        "total = total.reset_index()\n",
        "total = total.drop(['index'], axis=1)\n",
        "total\n",
        "total.to_csv('/content/drive/My Drive/senti_dataset/merged_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4neei2dSXVxI"
      },
      "source": [
        "# Shuffling of tweets dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "colab_type": "code",
        "id": "_AqdbzlFTBpT",
        "outputId": "600235ff-d851-4083-d53f-02678f0611b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>my god this book is like listening to a record...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>need to go to bed now im wide awake too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>seems like a lacking concentration today even ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>crochet liberation front featured in inside cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>scoop: HASHTAG hasselhoff rushed to the hospit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION USER_MENTION and USER_MENTION ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION hi newbies. come and tweet with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>1</td>\n",
              "      <td>USER_MENTION i thought i was being slick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>0</td>\n",
              "      <td>nooooooooooooo i cant hear max on the radio!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>1</td>\n",
              "      <td>just woke up!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         polarity                                           sentence\n",
              "0               0  my god this book is like listening to a record...\n",
              "1               0            need to go to bed now im wide awake too\n",
              "2               0  seems like a lacking concentration today even ...\n",
              "3               1  crochet liberation front featured in inside cr...\n",
              "4               0  scoop: HASHTAG hasselhoff rushed to the hospit...\n",
              "...           ...                                                ...\n",
              "1599995         1   USER_MENTION USER_MENTION and USER_MENTION ar...\n",
              "1599996         1   USER_MENTION hi newbies. come and tweet with ...\n",
              "1599997         1          USER_MENTION i thought i was being slick \n",
              "1599998         0    nooooooooooooo i cant hear max on the radio!!! \n",
              "1599999         1                                     just woke up! \n",
              "\n",
              "[1600000 rows x 2 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/senti_dataset/train_preprocessed_0and1.csv', header=None)\n",
        "df = df.drop([0], axis=1)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df.rename(columns={1: \"polarity\", 2: \"sentence\"})\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PUGdAJNgWDpj"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/My Drive/senti_dataset/tweet_shuffled.csv')"
      ]
    }
  ]
}